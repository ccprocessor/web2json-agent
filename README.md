<div align="center">

# üåê web2json-agent

**Stop Coding Scrapers, Start Getting Data ‚Äî from Hours to Seconds**

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![LangChain](https://img.shields.io/badge/LangChain-1.0+-00C851?style=for-the-badge&logo=chainlink&logoColor=white)](https://www.langchain.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-Compatible-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com)
[![PyPI](https://img.shields.io/badge/PyPI-1.1.2-blue?style=for-the-badge&logo=pypi&logoColor=white)](https://pypi.org/project/web2json-agent/)

[English](README.md) | [‰∏≠Êñá](docs/README_zh.md)

</div>

---

## üìã Demo


https://github.com/user-attachments/assets/6eec23d4-5bf1-4837-af70-6f0a984d5464


---

## üìä SWDE Benchmark Results

The SWDE dataset covers 8 vertical fields, 80 websites, and 124,291 pages

<div align="center">

| |Precision|Recall|F1 Score|
|--------|-------|-------|------|
|COT| 87.75 | 79.90 |76.95 |
|Reflexion| **93.28** | 82.76 |82.40 |
|AUTOSCRAPER| 92.49 | 89.13 |88.69 |
| Web2JSON-Agent | 91.50 | **90.46** |**89.93** |

</div>

---

## üöÄ Quick Start

### Install via pip

```bash
# 1. Install package
pip install web2json-agent

# 2. Initialize configuration
web2json setup
```

### Install for Developers

```bash
# 1. Clone the repository
git clone https://github.com/ccprocessor/web2json-agent
cd web2json-agent

# 2. Install in editable mode
pip install -e .

# 3. Initialize configuration
web2json setup
```

### Usage instructions

```bash
# Mode 1: Auto mode (Automatically select the fields to be extracted)
web2json -d html_samples/ -o output/result

# Mode 2: Predefined mode (Specify the fields to be extracted)
web2json -d html_samples/ -o output/result --interactive-schema
```

---

## üêç API Usage

### API 1: extract_data()

Generate data/code/schema from HTML files.

**Auto Mode** - Let AI automatically detect and extract all fields:

```python
from web2json import Web2JsonConfig, extract_data

config = Web2JsonConfig(
    name="news_auto",            # Run name (creates output/news_auto/)
    html_path="html_samples/",   # Folder containing HTML files
    iteration_rounds=3,          # How many samples AI uses to learn structure
    output_dir="output/",        # Where all results will be saved
    outputs=["data", "code", "schema"]     # What to keep: parsed data + generated parser + schema(Contains XPath)
)

result_dir = extract_data(config)
print("Saved to:", result_dir)
```

**Predefined Mode** - Extract only specified fields:

```python
from web2json import Web2JsonConfig, extract_data

config = Web2JsonConfig(
    name="news_schema",
    html_path="html_samples/",
    output_dir="output/",

    # Specify fields you want to extract
    schema={
        "title": "string",
        "author": "string",
        "publish_date": "string",
        "content": "string"
    },

    outputs=["data", "code", "schema"]  # Keep data + parser + schema
)

result_dir = extract_data(config)
print("Saved to:", result_dir)
```

**Configuration Parameters:**

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `name` | str | Required | Run name (creates subdirectory in output_dir) |
| `html_path` | str | Required | Directory containing HTML files |
| `iteration_rounds` | int | 3 | Number of HTML samples for learning |
| `output_dir` | str | "output" | Main output directory |
| `schema` | Dict | None | Field definitions (None=Auto, Dict=Predefined) |
| `outputs` | List[str] | ["data", "code", "schema"] | Output types to keep |

**Output Types:**

- `"data"` - Parsed JSON data files (saved in `result/` directory)
- `"code"` - Generated parser code (saved in `parsers/` directory)
- `"schema"` - Learned schema definition (saved in `schemas/` directory)

---

### API 2: parse_data()

Parse new HTML files using an existing trained parser.

```python
from web2json import Web2JsonConfig, parse_data

config = Web2JsonConfig(
    name="new_batch",
    html_path="new_html_samples/",                            # New HTML files to parse
    parser_path="output/news_schema/parsers/final_parser.py", # Previously trained parser
    output_dir="output/",
    outputs=["data"]                                          # Only keep parsed JSON data
)

result_dir = parse_data(config)
print("Saved to:", result_dir)
```

**Use Cases:**
- You already have a parser generated by web2json-agent
- Need to parse new batches of HTML with the same structure
- Production environments with incremental data processing

---

## üìÑ License

Apache-2.0 License

---

<div align="center">

**Made with ‚ù§Ô∏è by the web2json-agent team**

[‚≠ê Star us on GitHub](https://github.com/ccprocessor/web2json-agent) | [üêõ Report Issues](https://github.com/ccprocessor/web2json-agent/issues) | [üìñ Documentation](https://github.com/ccprocessor/web2json-agent)

</div>
